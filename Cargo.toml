[package]
name = "cerebras-rs"
version = "0.0.1"
authors = ["Cerebras AI <support@cerebras.ai>"]
description = "High-performance Rust SDK for Cerebras Inference API - Low-latency AI model inference powered by Cerebras Wafer-Scale Engines"
license = "MIT"
edition = "2024"
repository = "https://github.com/cerebras/cerebras-rs"
documentation = "https://docs.rs/cerebras-rs"
readme = "README.md"
keywords = ["cerebras", "ai", "llm", "inference", "api"]
categories = ["api-bindings", "asynchronous"]

[features]
default = ["rustls-tls"]
rustls-tls = ["reqwest/rustls-tls"]
native-tls = ["reqwest/native-tls"]

[dependencies]
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
serde_repr = "0.1"
url = "2.5"
uuid = { version = "1.6", features = ["serde", "v4"] }
chrono = { version = "0.4", features = ["serde"] }
base64 = "0.22"

reqwest = { version = "0.12", default-features = false, features = ["json", "multipart", "stream"] }
tokio = { version = "1.35", features = ["macros", "rt-multi-thread"] }
async-trait = "0.1"

# Streaming dependencies
tokio-stream = { version = "0.1" }
futures-util = { version = "0.3" }
eventsource-stream = { version = "0.2" }
pin-project-lite = { version = "0.2" }

# Error handling
thiserror = "2.0"
anyhow = "1.0"
futures = "0.3.31"

[dev-dependencies]
tokio-test = "0.4"
mockito = "1.2"
wiremock = "0.6"
pretty_assertions = "1.4"

[[example]]
name = "chat_completion"

[[example]]
name = "streaming"

[[example]]
name = "function_calling"
